{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pymysql\n",
    "import re\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from konlpy.tag import Kkma\n",
    "import pandas as pd\n",
    "import ast\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "DATABASE_NAME = \"chats\"\n",
    "HOST_NAME = \"localhost\"\n",
    "USER_ID = \"root\"\n",
    "USER_PASSWORD = \"rootPW1!\"\n",
    "CHARSET = \"utf8\"\n",
    "TXT_FOLDER_PATH = \"chats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pymysql.connect(host=HOST_NAME, user=USER_ID, passwd=USER_PASSWORD, charset=CHARSET)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'USE %s ;'%DATABASE_NAME\n",
    "cursor.execute(sql)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'SELECT * FROM indexes;'\n",
    "cursor.execute(sql)\n",
    "conn.commit()\n",
    "rows=cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=[]\n",
    "for row in rows :\n",
    "    if row[1]<10:\n",
    "        table_name = str(row[0])+'0'+str(row[1])\n",
    "    else:\n",
    "        table_name = str(row[0])+str(row[1])\n",
    "    sql='SELECT * FROM %schats;' %table_name\n",
    "    cursor.execute(sql)\n",
    "    conn.commit()\n",
    "    results = cursor.fetchall()\n",
    "    for result in results:\n",
    "#         print(result)\n",
    "        item = [result[0], result[0].year, result[0].month, result[0].day, result[0].hour, result[0].minute, result[1], result[2]]\n",
    "        ls.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_origin = pd.DataFrame(ls,columns=['time','year','month','day','hour','minute','sender','message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_messages_by_sender(sender):\n",
    "    file_name='messages_by_'+sender+\"_\"+str(year)+'.txt'\n",
    "    with open (file_name,'w') as f :\n",
    "        f.write('\\n'.join(df_origin[df_origin['sender']==sender]['message']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_messages_by_sender_year(sender,year):\n",
    "    file_name='messages_by_'+sender+\"_\"+str(year)+'.csv'\n",
    "#     with open (file_name,'w') as f :\n",
    "    df_origin[(df_origin['sender']==sender) & (df_origin['year']==year)]['message'].to_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv_by_year(year):\n",
    "    file_name='messages_at_'+str(year)+'.csv'\n",
    "    df_origin[(df_origin['year']==year)].to_csv(file_name,index=False,encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv_all():\n",
    "    file_name='messages_all.csv'\n",
    "    df_origin.to_csv(file_name,index=False,encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv_by_year(2021)\n",
    "write_csv_by_year(2019)\n",
    "write_csv_by_year(2018)\n",
    "write_csv_by_year(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noun(msg_txt):\n",
    "    kkma = Kkma()\n",
    "    nouns = list()\n",
    "    pattern = re.compile(\"[ㄱ-ㅎㅏ-ㅣ]+\")\n",
    "    msg_txt = re.sub(pattern, \"\", msg_txt).strip()\n",
    "\n",
    "    if len(msg_txt) > 1 and len(msg_txt)<50:\n",
    "        pos = kkma.pos(msg_txt)\n",
    "        for keyword, type in pos:\n",
    "            # 고유명사 또는 보통명사\n",
    "            if (type == \"NNG\" or type == \"NNP\") and len(keyword)>1:\n",
    "                nouns.append(keyword)\n",
    "#         print(msg_txt, \"->\", nouns)\n",
    "\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_name(year):\n",
    "    return 'messages_at_'+str(year)+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_token_name(year):\n",
    "    return 'tokens_at_'+str(year)+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_21 = pd.read_csv(get_csv_name(2021))\n",
    "# csv_21['token']=csv_21['message'].apply(lambda x: get_noun(x))\n",
    "# csv_21=csv_21.dropna()\n",
    "# csv_21.to_csv(get_csv_token_name(2021), index=False,encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tokens_from_msgs(years):\n",
    "    for year in years :\n",
    "        c = pd.read_csv(get_csv_name(year))\n",
    "        c['token']=c['message'].apply(lambda x: get_noun(x))\n",
    "        c=c.dropna()\n",
    "        c.to_csv(get_csv_token_name(year), index=False,encoding='utf-8-sig')\n",
    "        print(str(year)+\" finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_tokens_from_msgs([2018,2019,2020,2021])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_wordcloud(kkma_result,sender='',year=0):\n",
    "    # List로 되어있는 열을 Row 단위로 분리\n",
    "    if sender=='':\n",
    "        tokens = pd.DataFrame(kkma_result[\"token\"].apply(lambda x: ast.literal_eval(x)).tolist())\n",
    "    else:\n",
    "        tokens = pd.DataFrame(kkma_result[kkma_result['sender']==sender][\"token\"].apply(lambda x: ast.literal_eval(x)).tolist())     \n",
    "    tokens[\"Date\"] = kkma_result[\"time\"]\n",
    "    tokens[\"Sender\"] = kkma_result[\"sender\"]\n",
    "    tokens[\"Message\"] = kkma_result[\"message\"]\n",
    "    tokens = tokens.set_index([\"Date\", \"Sender\", \"Message\"])\n",
    "    tokens = tokens.T.unstack().dropna().reset_index()\n",
    "    tokens.columns = [\"Date\", \"Speaker\", \"sntc\", \"index\", \"token\"]\n",
    "#     # 빈도수 집계\n",
    "    summary = tokens.groupby([\"token\"])[\"index\"].count().reset_index()\n",
    "    summary = summary.sort_values([\"index\"], ascending=[False]).reset_index(drop=True)\n",
    "\n",
    "    except_words=['내가','조아','이번','마자','나도','거지','구래','니야','무엇','정도','하다','자소','이상','할거','오늘','내일','사람']\n",
    "   # 특정 단어 필터링\n",
    "    summary = summary[summary[\"token\"].apply(lambda x: x not in except_words)]\n",
    "    summary = summary[summary[\"token\"].apply(lambda x: len(x) > 1)]\n",
    "    summary_top_50 = summary[:100]\n",
    "\n",
    "\n",
    "# 워드클라우드 생성\n",
    "    wc = WordCloud(background_color='white', width=2000, height=1500, font_path='./font/NanumGothic.ttf').generate(\" \".join(summary_top_50[\"token\"]))\n",
    "    plt.imshow(wc)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(sender+'`s Cloud('+str(year)+\")\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv=pd.read_csv(get_csv_token_name(2021))\n",
    "draw_wordcloud(csv)\n",
    "# print(res[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv=pd.read_csv(get_csv_token_name(2021))\n",
    "draw_wordcloud(csv,'A',2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv=pd.read_csv(get_csv_token_name(2021))\n",
    "draw_wordcloud(csv,'B',2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "csv=pd.read_csv(get_csv_token_name(2020))\n",
    "draw_wordcloud(csv,'A',2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv=pd.read_csv(get_csv_token_name(2020))\n",
    "draw_wordcloud(csv,'B',2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv=pd.read_csv(get_csv_token_name(2020))\n",
    "draw_wordcloud(csv,'B',2020)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
